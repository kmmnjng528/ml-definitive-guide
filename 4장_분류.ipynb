{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 파이썬 머신러닝 완벽 가이드 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/928/l9791158391928.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장. 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#분류(Classification)의-개요\" data-toc-modified-id=\"분류(Classification)의-개요-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>분류(Classification)의 개요</a></span></li><li><span><a href=\"#결정-트리(Decision-Tree)\" data-toc-modified-id=\"결정-트리(Decision-Tree)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>결정 트리(Decision Tree)</a></span><ul class=\"toc-item\"><li><span><a href=\"#결정-트리-모델의-특징\" data-toc-modified-id=\"결정-트리-모델의-특징-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>결정 트리 모델의 특징</a></span></li><li><span><a href=\"#결정-트리-파라미터\" data-toc-modified-id=\"결정-트리-파라미터-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>결정 트리 파라미터</a></span></li><li><span><a href=\"#결정-트리-모델의-시각화\" data-toc-modified-id=\"결정-트리-모델의-시각화-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>결정 트리 모델의 시각화</a></span></li><li><span><a href=\"#결정-트리-과적합(Overfitting)\" data-toc-modified-id=\"결정-트리-과적합(Overfitting)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>결정 트리 과적합(Overfitting)</a></span></li><li><span><a href=\"#결정-트리-실습---사용자-행동-인식-데이터-세트\" data-toc-modified-id=\"결정-트리-실습---사용자-행동-인식-데이터-세트-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>결정 트리 실습 - 사용자 행동 인식 데이터 세트</a></span></li></ul></li><li><span><a href=\"#앙상블-학습(Ensemble-Learning)\" data-toc-modified-id=\"앙상블-학습(Ensemble-Learning)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>앙상블 학습(Ensemble Learning)</a></span><ul class=\"toc-item\"><li><span><a href=\"#배깅\" data-toc-modified-id=\"배깅-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>배깅</a></span></li><li><span><a href=\"#부스팅\" data-toc-modified-id=\"부스팅-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>부스팅</a></span></li><li><span><a href=\"#보팅\" data-toc-modified-id=\"보팅-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>보팅</a></span></li></ul></li><li><span><a href=\"#랜덤-포레스트\" data-toc-modified-id=\"랜덤-포레스트-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>랜덤 포레스트</a></span><ul class=\"toc-item\"><li><span><a href=\"#랜덤포레스트의-개요-및-실습\" data-toc-modified-id=\"랜덤포레스트의-개요-및-실습-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>랜덤포레스트의 개요 및 실습</a></span></li><li><span><a href=\"#랜덤-포레스트-하이퍼-파라미터-및-튜닝\" data-toc-modified-id=\"랜덤-포레스트-하이퍼-파라미터-및-튜닝-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>랜덤 포레스트 하이퍼 파라미터 및 튜닝</a></span></li></ul></li><li><span><a href=\"#GBM\" data-toc-modified-id=\"GBM-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>GBM</a></span><ul class=\"toc-item\"><li><span><a href=\"#GBM의-개요-및-실습\" data-toc-modified-id=\"GBM의-개요-및-실습-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>GBM의 개요 및 실습</a></span></li><li><span><a href=\"#GBM의-하이퍼파라미터-및-튜닝\" data-toc-modified-id=\"GBM의-하이퍼파라미터-및-튜닝-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>GBM의 하이퍼파라미터 및 튜닝</a></span></li></ul></li><li><span><a href=\"#XGBoost(eXtra-Gradient-Boost)\" data-toc-modified-id=\"XGBoost(eXtra-Gradient-Boost)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>XGBoost(eXtra Gradient Boost)</a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost-개요\" data-toc-modified-id=\"XGBoost-개요-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>XGBoost 개요</a></span></li><li><span><a href=\"#XGBoost-설치하기\" data-toc-modified-id=\"XGBoost-설치하기-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>XGBoost 설치하기</a></span></li><li><span><a href=\"#파이썬-래퍼-XGBoost-하이퍼-파라미터\" data-toc-modified-id=\"파이썬-래퍼-XGBoost-하이퍼-파라미터-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>파이썬 래퍼 XGBoost 하이퍼 파라미터</a></span></li><li><span><a href=\"#파이썬-래퍼-XGBoost-적용---위스콘신-유방암-예측\" data-toc-modified-id=\"파이썬-래퍼-XGBoost-적용---위스콘신-유방암-예측-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측</a></span></li><li><span><a href=\"#사이킷런-래퍼-XGBoost의-개요-및-적용\" data-toc-modified-id=\"사이킷런-래퍼-XGBoost의-개요-및-적용-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>사이킷런 래퍼 XGBoost의 개요 및 적용</a></span></li></ul></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#분류-실습---캐글-산탄데르-고객-만족-예측\" data-toc-modified-id=\"분류-실습---캐글-산탄데르-고객-만족-예측-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>분류 실습 - 캐글 산탄데르 고객 만족 예측</a></span></li><li><span><a href=\"#분류-실습---캐글-신용카드-사기-검출\" data-toc-modified-id=\"분류-실습---캐글-신용카드-사기-검출-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>분류 실습 - 캐글 신용카드 사기 검출</a></span></li><li><span><a href=\"#스태킹-앙상블\" data-toc-modified-id=\"스태킹-앙상블-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>스태킹 앙상블</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류(Classification)의 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습은 레이블(Label), 즉 명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식입니다. 지도학습의 대표적인 유형인 **분류(Classification)**는 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측하는 것입니다.  \n",
    "\n",
    "분류는 다양한 머신러닝 알고리즘으로 구현할 수 있습니다.\n",
    "- 나이브 베이즈(Naive Bayes)\n",
    "- 로지스틱 회귀(Logistic Regression)\n",
    "- 결정 트리(Decision Tree)\n",
    "- 서포트 벡터 머신(Support Vector Machine)\n",
    "- 최소 근접(Nearest Neighbor) 알고리즘\n",
    "- 신경망(Neural Network)\n",
    "- 앙상블(Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서는 **앙상블 방법(Ensemble Method)**을 집중적으로 다룹니다. **정형 데이터의 예측 분석** 영역에서는 **앙상블**이 매우 높은 예측 성능으로 인해 많은 분석가와 데이터 과학자들에게 애용되고 있습니다.  \n",
    "\n",
    "앙상블은 서로 다른/또는 같은 알고리즘을 단순히 결합한 형태도 있으나, 일반적으로는 **배깅(Bagging)**과 **부스팅(Boosting)** 방식으로 나뉩니다. 배깅 방식의 대표인 **랜덤 포레스트(Random Forest)**는 뛰어난 예측 성능, 상대적으로 빠른 수행 시간, 유연성 등으로 많은 분석가가 애용하는 알고리즘입니다. 하지만 근래의 앙상블 방법은 **부스팅** 방식으로 지속해서 발전하고 있습니다. **그래디언트 부스팅(Gradient Boosting, GBM)**의 경우 뛰어난 예측 성능을 가지고 있지만, 수행 시간이 너무 오래 걸리는 단점으로 인해 최적화 모델 튜닝이 어려웠습니다. 하지만 **XGBoost**와 **LightGBM** 등 기존 그래디언트 부스팅의 예측 성능을 한 단계 발전시키면서도 수행 시간을 단축시킨 알고리즘이 계속 등장하면서 정형 데이터의 분류 영역에서 가장 활용도가 높은 알고리즘으로 자리잡았습니다.  \n",
    "\n",
    "이 장에서는 앙상블 방법의 개요와 **랜덤 포레스트**, **그래디언트 부스팅**의 전통적인 앙상블 기법뿐만 아니라 부스팅 계열의 최신 기법인 **XGBoost**와 **LightGBM**, 그리고 앙상블의 앙상블이라고 불리는 **스태킹(Stacking)** 기법에 대해 상세히 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결정 트리(Decision Tree)**는 ML 알고리즘 중 직관적으로 이해하기 쉬운 알고리즘입니다. 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만드는 것입니다.  \n",
    "\n",
    "- 규칙 노드(Decision Node): 규칙 조건\n",
    "- 리프 노드(Leaf Node): 결정된 클래스 값\n",
    "\n",
    "많은 규칙이 있다는 것은 곧 과적합으로 이어지기 쉽습니다. 즉, 트리의 깊이(depth)가 길어질수록 결정 트리의 예측 성능이 저하될 가능성이 높습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/dbj2000/post/9899931f-a1f1-4c00-bbbb-89d4834e1105/image.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능한 한 적은 결정 노드로 높은 예픅 정확도를 가지려면 데이터를 분류할 때 최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 결정 노드의 규칙이 정해져야 합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/dbj2000/post/80dbb250-6868-49e3-9898-01ac1fd23667/image.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "항아리의 균일도는 3 > 2 > 1 순입니다. 항아리를 데이터셋이라 생각한다면, 데이터셋의 균일도가 낮을수록(혼잡도가 높을수록) 데이터를 판단하는 데 있어 더 많은 정보가 필요합니다. 결정 노드는 정보 균일도가 높은 대이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만듭니다.  \n",
    "\n",
    "이러한 정보의 균일도를 측정하는 대표적인 방법은 **1) 엔트로피를 이용한 정보 이득(Information Gain) 지수**와 **2) 지니 계수**가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 엔트로피를 이용한 정보 이득\n",
    "- 지니 계수  \n",
    "\n",
    "(둘 다 1에 가까울수록 균일)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 트리 알고리즘을 사이킷런에서 구현한 **DecisionTreeClassifer**는 기본으로 **지니 계수**를 이용해 데이터 세트를 분할합니다.  \n",
    "1. 정보 이득이나 지니 계수가 높은 조건(균일)을 찾는다.\n",
    "2. 자식 트리 노드에 반복적으로 분할한다.\n",
    "3. 데이터가 모두 특정 분류에 속하게 되면 분할을 멈추고 분류를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 모델의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ 장점 ]**\n",
    "1. 정보의 '균일도'라는 룰을 기반으로 하고 있어 알고리즘이 쉽고 직관적이다.\n",
    "2. 룰이 매우 명확하기에 어떻게 규칙 노드와 리프 노드가 만들어지는지 시각화할 수 있다.\n",
    "3. 각 피처의 스케일링과 정규화 같은 전처리 작업이 필요 없다.\n",
    "\n",
    "**[ 단점 ]**\n",
    "1. 과적합으로 정확도가 떨어진다. (트리의 크기를 사전에 제한하는 것이 오히려 성능 튜닝에 더 도움이 된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **max_depth**  \n",
    "트리의 최대 깊이  \n",
    "디폴트 = None (완벽하게 클래스 결정값이 될 때까지 깊이를 계속 키우며 분할 하거나 노드가 가지는 데이터의 개수가 min_sample_split보다 작아질때까지 계속 깊이를증가 시킨다.)  \n",
    "깊이가 깊어지면 과적합하므로 주의  \n",
    "\n",
    "- **min_samples_split**  \n",
    "현재 샘플 개수를 보고 자식을 만들지 말지 결정함  \n",
    "디폴트 2 (작게 설정할수록 과적합 가능성 증가)  \n",
    "노드를 분할하기 위한 최소한의 샘플 데이터 수  \n",
    "과적합 제어 용도  \n",
    "\n",
    "- **min_samples_leaf**  \n",
    "샘플 개수가 이 값 이하가 되도록 부모 규칙을 변경함  \n",
    "디폴트 1  \n",
    "말단 노드가 되기 위한 최소한의 샘플 데이터 수  \n",
    "과적합 제어 용도  \n",
    "비대칭적 데이터(하나의 피처가 과도하게 많은 경우)에는 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정  \n",
    "\n",
    "- **max_features**  \n",
    "최적의 분할을 위해 고려할 최대 피처 개수  \n",
    "디폴트 = none (데이터 세트의 모든 피처를 사용해 분할)  \n",
    "max_features = sqrt/ auto : √(전체 피처 개수)  \n",
    "max_features = log2 : log2(피처 개수)  \n",
    "Int형으로 지정하면 대상 피처의 개수, float형으로 지정하면 전체 피처 중 대상 피처의 퍼센트  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 주요 파라미터는 뭘까? 그리드 서치할 때 주로 뭘 건드릴까? -> 알아보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 모델의 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphviz** 패키지를 사용하여 어떠한 규칙을 가지고 트리를 생성하는지 시각적으로 보여줄 수 있습니다. 사이킷런은 이러한 Graphviz 패키지와 쉽게 인터페이스 할 수 있도록 **export_graphviz() API**를 제공합니다.  \n",
    "\n",
    "Download Link: https://graphviz.org/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "붓꽃 데이터 세트에 결정 트리를 적용할 때 어떻게 서브 트리가 구성되고 만들어지는지 시각화해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:07.044885Z",
     "start_time": "2021-01-27T03:23:05.186741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=156, splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리\n",
    "iris_data = load_iris()\n",
    "X_train , X_test , y_train , y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                       test_size=0.2,  random_state=11)\n",
    "\n",
    "# DecisionTreeClassifer 학습. \n",
    "dt_clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:07.059891Z",
     "start_time": "2021-01-27T03:23:07.048871Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함. \n",
    "export_graphviz(dt_clf, out_file=\"tree.dot\", class_names=iris_data.target_names , \\\n",
    "feature_names = iris_data.feature_names, impurity=True, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:07.520937Z",
     "start_time": "2021-01-27T03:23:07.064828Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-616d2accb26c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 위에서 생성된 tree.dot 파일을 Graphviz 읽어서 Jupyter Notebook상에서 시각화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree.dot\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdot_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# 위에서 생성된 tree.dot 파일을 Graphviz 읽어서 Jupyter Notebook상에서 시각화 \n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음... 왜 안되지! 환경 변수 설정 다시 해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 결정 트리 알고리즘이 학습을 통해 규칙을 정하는 데 있어 **피처의 중요한 역할 지표**를 **DecisionTreeClassifier** 객체의 **feature_importance_** 속성으로 제공합니다. feature_importances_ 속성을 가져와 피처별로 중요도 값을 매핑하고 이를 막대그래프로 표현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:24.771441Z",
     "start_time": "2021-01-27T03:23:23.158890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.025 0.    0.555 0.42 ]\n",
      "sepal length (cm) : 0.025\n",
      "sepal width (cm) : 0.000\n",
      "petal length (cm) : 0.555\n",
      "petal width (cm) : 0.420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x188ffb6fbc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# feature importance 추출 \n",
    "print(\"Feature importances:\\n{0}\".format(np.round(dt_clf.feature_importances_, 3)))\n",
    "\n",
    "# feature별 importance 매핑\n",
    "for name, value in zip(iris_data.feature_names , dt_clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "# feature importance를 column 별로 시각화 하기 \n",
    "sns.barplot(x=dt_clf.feature_importances_ , y=iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 다른 알고리즘이 블랙박스라고 불리듯이 알고리즘 내부의 동작 원리가 복잡한 데 반해 결정 트리는 알고리즘 자체가 직관적이기 때문에 알고리즘과 관련된 요소를 시각적으로 표현할 수 있는 다양한 방안이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 과적합(Overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "청일점, 홍일점처럼 일부 이상치 데이터까지 분류하기 위해서 분할이 자주 일어나면 결정 기준 경계가 많아지게 됩니다. 이렇게 복잡한 모델은 학습 데이터셋의 특성과 약간만 다른 형태의 데이터셋이 들어오면 제대로 예측할 수 없게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 트리가 어떻게 학습 데이터를 분할해 예측을 수행하는지와 이로 인한 과적합 문제를 시각화에 대해 알아보겠습니다.\n",
    "\n",
    "사이킷런은 분류를 위한 테스트용 데이터를 쉽게 만들 수 있도록 **make_classificaion()** 함수를 제공합니다. 2개의 피처가 3가지 유형의 클래스 값을 가지는 데이터 세트를 만들고 이를 그래프 형태로 시각화하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:24.913570Z",
     "start_time": "2021-01-27T03:23:24.249Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title(\"3 Class values with 2 Features Sample data creation\")\n",
    "\n",
    "# 2차원 시각화를 위해서 feature는 2개, 결정값 클래스는 3가지 유형의 classification 샘플 데이터 생성. \n",
    "X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             n_classes=3, n_clusters_per_class=1,random_state=0)\n",
    "\n",
    "# plot 형태로 2개의 feature로 2차원 좌표 시각화, 각 클래스값은 다른 색깔로 표시됨. \n",
    "plt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, cmap='rainbow', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 트리 모델이 어떠한 결정 기준을 가지고 분할하면서 데이터를 분류하는지 확인할 것입니다. 이를 위해 별도의 visualize_boundary() 함수를 생성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:24.915566Z",
     "start_time": "2021-01-27T03:23:24.526Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Classifier의 Decision Boundary를 시각화 하는 함수\n",
    "def visualize_boundary(model, X, y):\n",
    "    fig,ax = plt.subplots()\n",
    "    \n",
    "    # 학습 데이타 scatter plot으로 나타내기\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim_start , xlim_end = ax.get_xlim()\n",
    "    ylim_start , ylim_end = ax.get_ylim()\n",
    "    \n",
    "    # 호출 파라미터로 들어온 training 데이타로 model 학습 . \n",
    "    model.fit(X, y)\n",
    "    # meshgrid 형태인 모든 좌표값으로 예측 수행. \n",
    "    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),np.linspace(ylim_start,ylim_end, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    # contourf() 를 이용하여 class boundary 를 visualization 수행. \n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap='rainbow', clim=(y.min(), y.max()),\n",
    "                           zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 이상치(Outlier) 데이터까지 분류하기 위해 분할이 자주 일어나서 결정 기준 경계가 매우 많아졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:24.942493Z",
     "start_time": "2021-01-27T03:23:24.860Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 특정한 트리 생성 제약없는 결정 트리의 Decsion Boundary 시각화.\n",
    "dt_clf = DecisionTreeClassifier().fit(X_features, y_labels)\n",
    "visualize_boundary(dt_clf, X_features, y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 min_samples_leaf = 6을 설정해 6개 이하의 데이터는리프 노드를 생성할 수 있도록 리프 노드 생성 규칙을 완화하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:25.060278Z",
     "start_time": "2021-01-27T03:23:25.041329Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a3e7ab877bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# min_samples_leaf=6 으로 트리 생성 조건을 제약한 Decision Boundary 시각화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdt_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvisualize_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_features' is not defined"
     ]
    }
   ],
   "source": [
    "# min_samples_leaf=6 으로 트리 생성 조건을 제약한 Decision Boundary 시각화\n",
    "dt_clf = DecisionTreeClassifier( min_samples_leaf=6).fit(X_features, y_labels)\n",
    "visualize_boundary(dt_clf, X_features, y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치에 크게 반응하지 않으면서 좀 더 일반화된 분류 규칙에 따라 분류됐음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 실습 - 사용자 행동 인식 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:25.434278Z",
     "start_time": "2021-01-27T03:23:25.430320Z"
    }
   },
   "outputs": [],
   "source": [
    "# 일단 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 학습(Ensemble Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**앙상블 학습**을 통한 분류는 여러 개의 분류기(Classifeir)를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법을 말합니다. 앙상블 학습을 집단 지성에 비유할 수 있습니다. 대부분의 정형 데이터 분류 시에는 앙상블이 뛰어난 성능을 나타내고 있습니다. 쉽고 편하면서도 강력한 성능을 보유하고 있는 것이 바로 앙상블 학습의 특징입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 학습의 유형은 전통적으로 **보팅(Voting)**, **배깅(Vagging)**, **부스팅(Boosting)**의 세 가지로 나눌 수 있으며, 이외에도 **스태킹(Stacking)**을 포함한 다양한 앙상블 방법이 있습니다.  \n",
    "\n",
    "**< 보팅과 배깅 >**  \n",
    "**보팅**과 **배깅**은 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식입니다. **보팅**의 경우 일반적으로 **서로 다른** 알고리즘을 가진 분류기를 결합하는 것이고, **배깅**의 경우 각각의 분류기가 **모두 같은 유형**의 알고리즘 기반이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 수행하는 것입니다. 대표적인 배깅 방식이 바로 **랜덤 포레스트** 알고리즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/kjpark4321/post/c5208df8-0c2e-48b6-a727-b8996633d167/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-14%20%EC%98%A4%EC%A0%84%201.02.01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배깅\n",
    "오른쪽 그림의 배깅 방식은 단일 ML 알고리즘(결정 트리)으로 여러 분류기가 학습으로 개별 예측을 하는데, **학습하는 데이터 세트**가 보팅 방식과 다릅니다. 개별 분류기에 할당된 학습 데이터는 원본 학습 데이터를 샘플링해 추출합니다. 이렇게 개별 Classifier에게 데이터를 샘플링해서 추출하는 방식을 **부트스트래핑(Bootstrapping)** 분할 방식이라고 부릅니다. 이렇게 부트스트래핑 방식으로 샘플링된 데이터셋에 대해서 학습을 통해 개별적인 예측을 수행한 결과를 보팅을 통해서 최종 예측 결과를 선정하는 방식이 바로 배깅 앙상블 방식입니다.  \n",
    "참고로, 교차 검증이 데이터셋 간에 중첩을 허용하지 않는 것과 다르게 배깅 방식은 중첩을 허용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부스팅\n",
    "부스팅은 여러 개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에게는 **가중치(weight)**를 부여하면서 학습과 예측을 진행하는 것입니다. 그래디언트 부스트, XGBoost, LightGBM이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 보팅\n",
    "- 하드 보팅(Hard Voting)  \n",
    "- 소프트 보팅(Soft Voting)  \n",
    "\n",
    "보팅 방법에는 하드 보팅과 소프트 보팅이 있습니다. **하드 보팅**은 다수결 원칙과 비슷합니다. 예측한 결괏값들중 다수의 분류기가 결정한 예측값을 최종 보팅 결괏값으로 선정합니다. **소프트 보팅**은 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결괏값으로 선정합니다. 일반적으로는 **소프트 보팅**이 하드 보팅보다는 예측 성능이 좋아서 더 많이 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/kjpark4321/post/bff303e6-0e82-4066-9032-bad1c0239a21/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-14%20%EC%98%A4%EC%A0%84%201.11.58.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< 보팅 분류기 >**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 보팅 방식의 앙상블을 구현한 **VotingClassifier** 클래스를 제공하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보팅 방식의 앙상블을 이용해 위스콘신 유방암 데이터 세트를 예측해보겠습니다. 위스콘신 유방암 데이터 세트는 유방암의 악성 종양, 양성종양 여부를 결정하는 이진 분류 데이터 세트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:27.130195Z",
     "start_time": "2021-01-27T03:23:27.097892Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:27.531613Z",
     "start_time": "2021-01-27T03:23:27.465776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:27.844763Z",
     "start_time": "2021-01-27T03:23:27.837780Z"
    }
   },
   "outputs": [],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:28.072153Z",
     "start_time": "2021-01-27T03:23:28.065183Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보팅 분류기의 정확도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:28.835549Z",
     "start_time": "2021-01-27T03:23:28.773210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델의 정확도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:29.249962Z",
     "start_time": "2021-01-27T03:23:29.195110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 정확도: 0.9386\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델의 정확기보다 보팅 분류기의 정확도가 높게 나타났습니다. 보팅으로 여러 개의 기반 분류기를 결합한다고 해서 무조건 기반 분류기보다 예측 성능이 향상되지는 않습니다. 그럼에도 불구하고 지금 소개하는 보팅을 포함해 배깅과 부스팅 등의 앙상블 방법은 전반적으로 다른 단일 ML 알고리즘보다 뛰어난 예측 성능을 가지는 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보팅과 스태킹 등은 서로 다른 알고리즘을 기반으로 하고 있지만, 배깅과 부스팅은 대부분 결정 트리 알고리즘을 기반으로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트의 개요 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**배깅(Bagging)**은 앞에서 소개한 보팅과는 다르게, 같은 알고리즘으로 여러 개의 분류기를 만들어서 보팅으로 최종 결정하는 알고리즘입니다. 배깅의 대표적인 알고리즘은 **랜덤 포레스트**입니다. 비교적 빠른 수행 속도를 가지고 있으며 다양한 영역에서 높은 예측 성능을 보이고 있습니다. 랜덤 포레스트의 기반 알고리즘은 결정 트리로서, 결정 트리의 쉽고 직관적인 장점을 그대로 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/kjpark4321/post/f0f5c31d-c4c9-4e2a-8bb4-53548aad5b77/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-14%20%EC%98%A4%EC%A0%84%201.53.55.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트의 개별 트리가 학습하는 데이터셋은 전체 데이터에서 일부가 중첩되게 샘플링된 데이터셋입니다. 이렇게 여러 개의 데이터셋을 중첩되게 분리하는 것을 **부트스트래핑(Bootstraping)** 분할 방식이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/kjpark4321/post/5c47476a-7abf-45b8-a5ba-b442305933d8/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-14%20%EC%98%A4%EC%A0%84%201.57.25.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 RandomForestClassifer 클래스를 통해 랜덤 포레스트 기반의 분류를 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 행동 인식 예측 데이터셋을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:30.282890Z",
     "start_time": "2021-01-27T03:23:30.278900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:30.806127Z",
     "start_time": "2021-01-27T03:23:30.772218Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:31.511243Z",
     "start_time": "2021-01-27T03:23:31.502266Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, cancer.target, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:32.801593Z",
     "start_time": "2021-01-27T03:23:32.529288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트 하이퍼 파라미터 및 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:23:33.756940Z",
     "start_time": "2021-01-27T03:23:33.751947Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:02.611595Z",
     "start_time": "2021-01-27T03:23:33.760922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 150}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[50, 100, 150, 200],\n",
    "    'max_depth':[6, 8, 10, 12],\n",
    "    'min_samples_split':[6, 8, 10, 12],\n",
    "    'min_samples_leaf':[6, 8, 10, 12]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1) # n_jobs=-1: 컴퓨터의 모든 코어를 사용\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:03.111233Z",
     "start_time": "2021-01-27T03:25:03.104251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9494261534894505"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 셋에 대해 성능을 측정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:05.275634Z",
     "start_time": "2021-01-27T03:25:04.761731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=150, min_samples_split=6,\n",
    "                                min_samples_leaf=6, max_depth=6,\n",
    "                                random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트는 결정 트리와 마찬가지로 피처 중요도를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:06.197813Z",
     "start_time": "2021-01-27T03:25:06.190830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # 결과를 셀 아래 inline으로 표시 (? 무슨 말이지)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline # 결과를 셀 아래 inline으로 표시 (? 무슨 말이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:06.221747Z",
     "start_time": "2021-01-27T03:23:31.836Z"
    }
   },
   "outputs": [],
   "source": [
    "ftr_importances_values = rf_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM의 개요 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부스팅 알고리즘은 여러 개의 약한 학습기를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식입니다. 부스팅의 대표적인 구현은 **AdaBoost**와 **그래디언트 부스트(GBM)**이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 다음 그림을 통해 에이다부스트가 어떻게 학습을 진행하는지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tkdguq05.github.io/images/adaboost.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 약한 학습기는 각각 가중치를 부여해 결합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GBM(Gradient Boost Machine)**도 에이다부스트와 유사하나, 가중치 업데이트를 경사 하강법을 이용하는 것이 큰 차이입니다. 분류의 결과값을 y, 예측함수를 F(x)라고 하면, 오류식 h(x)=y−F(x)가 됩니다. 이 오류식을 최소화하는 방향을 가지고 반복적으로 가중치 값을 업데이트하는 것이 **경사 하강법(Gradient Descent)**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:06.241695Z",
     "start_time": "2021-01-27T03:23:33.052Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 GBM이 랜덤 포레스트보다는 예측 성능이 뛰어난 경우가 많습니다. 그러나 수행 시간이 오래 걸리고, 하이퍼 파라미터 튜닝 노력도 더 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM의 하이퍼파라미터 및 튜닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/bCJsjz/btqUTlWmDN3/KVG2oHcBUS8bSZMysXFtsk/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **learning_rate**는 0~1 사이의 값을 자정할 수 있습니다. 기본값은 0.1이며 너무 작은 값을 적용하면 업데이트 되는 값이 작아져서 최소 오류 값을 찾아 예측 성능이 높아질 가능성이 있습니다.(?) 너무 작게 설정하면 모든 weak learner의 반복이 완료돼도 최소 오류 값을 찾지 못할 수 있으며, 큰 값을 적용하면 최소 오류 값을 찾지 못하고 그냥 지나쳐 버려 예측 성능이 떨어질 가능성이 높아집니다. (그러나 빠른 수행이 가능합니다.)  \n",
    "이러한 특성 때문에 learning_rate는 n_estimators와 상호 보완적으로 조합해 사용합니다. learning_rate를 작게 하고 n_estimators를 크게 하면 더 이상 성능이 좋아지지 않는 한계점까지는 예측 성능이 좋아질 수 있습니다. (하지만 수행 시간이 너무 오래 걸리며, 성능이 현격히 좋아지지는 않습니다.)  \n",
    "\n",
    "- **subsample**의 기본값은 1입니다. 과적합이 염려되는 경우 subsample을 1보다 작은 값으로 설정합니다.  \n",
    "Q. 그럼 subsample을 1로 설정하는 경우는 언제일까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:06.260643Z",
     "start_time": "2021-01-27T03:23:34.181Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_cv = GridSearchCV(gb_clf, param_grid=params, cv=2, n_jobs=-1, verbose=1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('{} 수행 시간: {:.4f}'.format(grid_cv.__class__.__name__, time.time() - start_time))\n",
    "print('best parameters: {}'.format(grid_cv.best_params_))\n",
    "print('best score: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:25:06.262638Z",
     "start_time": "2021-01-27T03:23:34.699Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm_clf = GradientBoostingClassifier(n_estimators=500, \n",
    "                                     learning_rate=0.05,\n",
    "                                     random_state=0)\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "pred = gbm_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('{}의 test score: {:.4f}'.format(gbm_clf.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. train보다 test가 높게 나왔네 뭔가 잘못된걸까?  \n",
    "책에서도 test가 더 높게 나왔네 괜찮나보다! (p.222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost(eXtra Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런 래퍼 XGBoost의 개요 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 실습 - 캐글 산탄데르 고객 만족 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 실습 - 캐글 신용카드 사기 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
