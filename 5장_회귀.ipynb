{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 파이썬 머신러닝 완벽 가이드 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/928/l9791158391928.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5장. 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#회귀-소개\" data-toc-modified-id=\"회귀-소개-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>회귀 소개</a></span></li><li><span><a href=\"#단순-선형-회귀를-통한-이해\" data-toc-modified-id=\"단순-선형-회귀를-통한-이해-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>단순 선형 회귀를 통한 이해</a></span></li><li><span><a href=\"#비용-최소화하기---경사-하강법(Gradient-Descent)-소개\" data-toc-modified-id=\"비용-최소화하기---경사-하강법(Gradient-Descent)-소개-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>비용 최소화하기 - 경사 하강법(Gradient Descent) 소개</a></span></li><li><span><a href=\"#사이킷런-LinearRegression을-이용한-보스턴-주택-가격-예측\" data-toc-modified-id=\"사이킷런-LinearRegression을-이용한-보스턴-주택-가격-예측-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측</a></span></li><li><span><a href=\"#다항-회귀와-과(대)적합-/-과소적합-이해\" data-toc-modified-id=\"다항-회귀와-과(대)적합-/-과소적합-이해-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>다항 회귀와 과(대)적합 / 과소적합 이해</a></span></li><li><span><a href=\"#규제-선형-모델---릿지,-라쏘,-엘라스틱넷\" data-toc-modified-id=\"규제-선형-모델---릿지,-라쏘,-엘라스틱넷-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷</a></span></li><li><span><a href=\"#로지스틱-회귀\" data-toc-modified-id=\"로지스틱-회귀-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>로지스틱 회귀</a></span></li><li><span><a href=\"#회귀-트리\" data-toc-modified-id=\"회귀-트리-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>회귀 트리</a></span></li><li><span><a href=\"#회귀-실습---자전거-대여-수요-예측\" data-toc-modified-id=\"회귀-실습---자전거-대여-수요-예측-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>회귀 실습 - 자전거 대여 수요 예측</a></span></li><li><span><a href=\"#회귀-실습---캐글-주택-가격:-고급-회귀-기법\" data-toc-modified-id=\"회귀-실습---캐글-주택-가격:-고급-회귀-기법-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>회귀 실습 - 캐글 주택 가격: 고급 회귀 기법</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습은 **분류**와 **회귀** 두 가지 유형으로 나뉩니다. 이 두 가지 기법의 가장 큰 차이는 **분류**는 예측값이 카테고리와 같은 이산형 클래스 값이고, **회귀**는 연속형 숫자 값이라는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**회귀(Regression) 분석**은 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용한 통계적 기법입니다. 통계학 용어를 빌리자면 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법을 통칭합니다.  \n",
    "머신러닝 관점에서 보면 **독립변수**는 **피처**에 해당되며 **종속변수**는 **결정 값**입니다. 핵심은 피처와 결정 값 데이터 기반에서 학습을 통해 **최적의 회귀 계수**를 찾아내는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 가지 회귀 중에서 **선형 회귀**가 가장 많이 사용됩니다. 실제 값과 예측값의 차이(오류의 제곱값)를 최소화하는 직선형 회귀선을 최적화하는 방식입니다.  \n",
    "선형 회귀 모델은 **규제(Regularization)** 방법에 따라 다시 별도의 유형으로 나눌 수 있습니다. **규제**는 일반적인 선형 회귀의 과적합 문제를 해결하기 위해서 **회귀 계수에 페널티 값을 적용하는 것**을 말합니다. 다음은 대표적인 선형 회귀 모델입니다.  \n",
    "\n",
    "- 일반 선형 회귀\n",
    "- 릿지(Ridge)\n",
    "- 라쏘(Lasso)\n",
    "- 엘라스틱넷(ElasticNet)\n",
    "- 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순 선형 회귀를 통한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 가장 간단한 단순 선형 회귀를 예로 들어 살펴보겠습니다.  \n",
    "\n",
    "단순 선형 회귀는 독립 변수도 하나, 종속변수도 하나인 선형 회귀입니다. 실제 값과 회귀 모델의 차이에 따른 오류 값을 남은 오류, 즉 **잔차**라고 부릅니다. **최적의 회귀 모델**을 만든다는 것은 바로 **전체 데이터의 잔차(오류 값) 합이 최소가 되는 모델을 만든다**는 의미입니다. 동시에 **오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다**는 의미도 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://1.bp.blogspot.com/-Zyw8lHq8P9I/WZ_kwcmeykI/AAAAAAAAL9w/nFvULbIZWCMC2PVdn-FT4EDqofoJlIYJACK4BGAYYCw/s1600/1.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 오류의 합을 계산할 때는 **절댓값을 취해서 더하거나**(**MAE**, Mean Absolute Error), **오류 값의 제곱을 구해서 더하는 방식**(**RSS**, Residaul Sum of Square)을 취합니다. 일반적으로 **RSS** 방식으로 오류 합을 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSS를 최소로하는 회귀 계수(w0. w1)를 학습을 통해 찾는 것이 머신러닝 기반 회귀의 핵심입니다. 일반적으로 RSS는 학습 데이터의 건수로 나누어서 정규화된 식으로 표현합니다. 이 RSS를 비용 함수라고 하며, 머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 이 비용 함수가 반환하는 값(즉, 오류 값)을 지속해서 감소시키고 최종적으로는 더 이상 감소하지 않는 최소의 오류 값을 구하는 것입니다. 비용 함수를 **손실 함수(loss function)** 라고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비용 최소화하기 - 경사 하강법(Gradient Descent) 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다항 회귀와 과(대)적합 / 과소적합 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 실습 - 자전거 대여 수요 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 실습 - 캐글 주택 가격: 고급 회귀 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
